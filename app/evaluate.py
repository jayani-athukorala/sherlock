# Imports
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import context_precision, faithfulness, answer_relevancy, context_recall
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import OllamaEmbeddings
from app.rag import retrieve_context, answer_question

# Models use to evaluate context and answers generated by Sherlock
llm = ChatOllama(
    model="llama3",
    base_url="") # To be implemented in docke compose
embeddings = OllamaEmbeddings(
    model="llama3",
    base_url="") # To be implemented in docke compose

# Evaluation Dataset
questions = [ "What was Mrs. Hudson's alibi?", 
             "Who was seen leaving the manor at midnight?", 
             "Did the butler have a motive?" ] 
ground_truths = [ "I don't have enough evidence to answer that.",
                  "Sir Robert was seen leaving the house at twelve oâ€™clock at night by the butler, Stephens.", 
                  "I don't have enough evidence to answer that." ]

# Evaluation rows
eval_rows = { "question": [], "answer": [], "contexts": [], "ground_truth": [] }


def generate_sample():
    # Clear previous results 
    eval_rows["question"] = [] 
    eval_rows["answer"] = [] 
    eval_rows["contexts"] = [] 
    eval_rows["ground_truth"] = [] 
    
    for question, ground_truth in zip(questions, ground_truths):
        # Retrieve context 
        context = retrieve_context(question) 
        
              
        # Generate answer 
        answer = answer_question(question) 
        
        # Append to evaluation rows 
        eval_rows["question"].append(question) 
        eval_rows["answer"].append(answer) 
        eval_rows["contexts"].append(context)
        eval_rows["ground_truth"].append(ground_truth) 
        
    return eval_rows

def test_rag_system():
    
    eval_rows = generate_sample()
    dataset = Dataset.from_dict(eval_rows)
    results = evaluate(
        dataset,
        metrics=[context_precision, faithfulness, answer_relevancy, context_recall],
        llm=llm,
        embeddings=embeddings
    )
    return results
